import streamlit as st
from llama_index.llms.openai import OpenAI
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
import os
from dotenv import load_dotenv
import argparse
from correcao_e_extracao import processar_busca, obter_latitude_longitude_google
from cabecalho import gerar_cabecalho

# Carregar as vari√°veis do arquivo .env
load_dotenv()

# Definir o ambiente headless para desabilitar o bot√£o de deploy
os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"

# os.environ["OPENAI_API_KEY"] = '' # sua chave aqui caso queira rodar script manualmente e debugar
# os.environ["GOOGLE_GEOCODING_API_KEY"] = '' # sua chave aqui caso queira rodar script manualmente e debugar

def gerar_prompt(busca):
    prompt_parts = ["Estou buscando restaurantes com os seguintes crit√©rios abaixo:"]

    # Nome do restaurante
    if busca.get('nome'):
        prompt_parts.append(f"- Nome do restaurante: {busca['nome']}")

    # Nota m√©dia m√≠nima
    if busca.get('nota_media'):
        prompt_parts.append(f"- Nota m√©dia m√≠nima: {busca['nota_media']}")

    # Avalia√ß√µes m√≠nimas
    if busca.get('avaliacoes'):
        prompt_parts.append(f"- Pelo menos {busca['avaliacoes']} avalia√ß√µes")

    # Categoria
    if busca.get('categoria'):
        prompt_parts.append(f"- Categoria: {busca['categoria']}")

    # Perfil de pre√ßo
    if busca.get('perfil_preco'):
        prompt_parts.append(f"- Perfil de pre√ßo: {busca['perfil_preco']}")

    # Taxa de entrega gr√°tis
    if busca.get('buscando_por_taxa_gratis'):
        prompt_parts.append(f"- Entrega gr√°tis: Sim")

    # Limite de taxa de entrega
    if busca.get('taxa_de_entrega_limite'):
        prompt_parts.append(f"- Limite da taxa de entrega: at√© {busca['taxa_de_entrega_limite']} reais")

    # Pratos
    if busca.get('pratos'):
        prompt_parts.append("- Pratos desejados:")
        for prato in busca['pratos']:
            prato_desc = f"  - {prato['nome']}"
            if prato.get('preco_maximo'):
                prato_desc += f" (at√© {prato['preco_maximo']} reais)"
            prompt_parts.append(prato_desc)

    # Endere√ßo
    if busca.get('endereco_entrega') and not busca.get('endereco_indefinido'):
        endereco = busca['endereco_entrega']
        endereco_parts = []
        if endereco.get('rua'):
            endereco_parts.append(f"Rua: {endereco['rua']}")
        if endereco.get('numero'):
            endereco_parts.append(f"N√∫mero: {endereco['numero']}")
        if endereco.get('bairro'):
            endereco_parts.append(f"Bairro: {endereco['bairro']}")
        if endereco.get('cidade'):
            endereco_parts.append(f"Cidade: {endereco['cidade']}")
        if endereco.get('estado'):
            endereco_parts.append(f"Estado: {endereco['estado']}")
        
        # Obter latitude e longitude usando a API do Google
        coordenadas = obter_latitude_longitude_google(endereco)
        
        if coordenadas:
            latitude, longitude = coordenadas
            prompt_parts.append(f"- Latitude: {latitude}, Longitude: {longitude}, buscando restaurantes em um raio de 5 km")

    prompt_final = "\n".join(prompt_parts)

    print(f'\n{prompt_final}')

    return prompt_final

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Sistema de Recomenda√ß√£o de Restaurantes", page_icon="üçΩÔ∏è", layout="centered", initial_sidebar_state="auto", menu_items=None)

gerar_cabecalho()

st.markdown("<br><h6>Uma maneira disruptiva para se pedir comida</h6>", unsafe_allow_html=True)

# Inicializa o hist√≥rico de mensagens
if "messages" not in st.session_state.keys():
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "Como posso te ajudar? me diga que tipo de comida voc√™ pretende comer e eu posso te indicar diversos restaurantes!",
        }
    ]

parser = argparse.ArgumentParser(description='Tratar dados')
parser.add_argument('--diretorio', type=str, help='Diretorio aonde se encontra arquivo que vamos processar', required=True)

args = parser.parse_args()

diretorio = args.diretorio

@st.cache_resource(show_spinner=False)
def load_data():
    reader = SimpleDirectoryReader(input_dir=diretorio, recursive=True)
    docs = reader.load_data()
    Settings.llm = OpenAI(
        model="gpt-3.5-turbo",
        temperature=1,
        system_prompt="""Voc√™ √© um especialista em recomenda√ß√µes de restaurantes. Seu trabalho √© sugerir restaurantes com base nos crit√©rios que o usu√°rio fornecer.""",
    )
    index = VectorStoreIndex.from_documents(docs)
    return index

index = load_data()

# Inicializa o motor de chat com LlamaIndex
if "chat_engine" not in st.session_state.keys():
    st.session_state.chat_engine = index.as_chat_engine(
        chat_mode="condense_question", verbose=True, streaming=True
    )

# Captura a entrada do usu√°rio
if prompt := st.chat_input("Digite suas prefer√™ncias para recomenda√ß√£o de restaurantes"):
    st.session_state.messages.append({"role": "user", "content": prompt})

# Exibe o hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar=("üë§" if message["role"] == "user" else "ü§ñ")):
        st.write(message["content"])

# Gera a resposta com base na entrada do usu√°rio
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant", avatar="ü§ñ"):
        # Processa a √∫ltima mensagem do usu√°rio usando `processar_buscas`
        user_input = st.session_state.messages[-1]["content"]
        
        # Chama `processar_buscas` para analisar a entrada do usu√°rio e gerar um objeto de busca
        busca = processar_busca(user_input)

        # Gera o prompt com base na extra√ß√£o dos dados
        prompt_gerado = gerar_prompt(busca)

        formatacao_saida = ("""Sempre exiba a resposta seguindo este padr√£o abaixo de exemplo em markdown, caso voc√™ responda um restaurante ou N restaurantes
        Restaurante: {nome}
        Categoria: {categoria}
        Avalia√ß√µes: {avaliacoes} avalia√ß√µes
        Nota m√©dia: {nota_media} (com duas casas decimais apenas)
        Dist√¢ncia: Aproximadamente {distancia_centroid} km do centro de S√£o Paulo
        Perfil de Pre√ßo: {prefil_preco}

        Taxas de Entrega: {taxa_1000_metros, taxa_2000_metros, taxa_3000_metros e taxa_4000_metros}
            At√© 1 km: Gr√°tis
            De 1 km a 2 km: R$ 2,00
            De 2 km a 3 km: R$ 6,00
            De 3 km a 4 km: R$ 9,00
        Pratos: {pratos}
            Picanha na Brasa - R$ 85,00
            Costela de Porco - R$ 70,00
            Cordeiro Assado - R$ 90,00
        """)

        busca_final = (f""" 
        O usuario digitou isto aqui: 
                       {user_input}   
                        
        Eu consegui extrair estas informa√ß√µes para a busca sair melhor:
                       {prompt_gerado}    

        Sempre formate a resposta com os dados disponiveis dos restaurantes em markdown
        Sempre que retorna a taxa de entrega, seja em reais ex.: R$10.00
        N√£o retorne o campo localiza√ß√£o
        Sempre retorne:
            Nome
            Avalia√ß√µes
            Categoria
            Note Media
            Perfil Pre√ßo
            Taxas de Entrega
                At√© 1km, usar valor do campo taxa_1000_metros pre√ßo em reais
                At√© 2km, usar valor do campo taxa_2000_metros pre√ßo em reais
                At√© 3km, usar valor do campo taxa_3000_metros pre√ßo em reais
                At√© 4km, usar valor do campo taxa_4000_metros pre√ßo em reais
            Pratos
        """)

        print(busca_final)
        
        # Chama o motor de chat para gerar a resposta com base no prompt gerado
        response_stream = st.session_state.chat_engine.stream_chat(busca_final)
        st.write_stream(response_stream.response_gen)

        message = {"role": "assistant", "content": response_stream.response}
        # Adiciona a resposta ao hist√≥rico de mensagens
        st.session_state.messages.append(message)